{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for feature extraction:\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio data directories:\n",
    "AUDIO_DIR = '../Data/genres/'\n",
    "TEST_DIR = '../Data/test_songs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for genres label encoding:\n",
    "GENRES = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4,\n",
    "          'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_songs(X, window, overlap):\n",
    "    \"\"\"\n",
    "    Function to split a song into multiple songs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Temporary lists to hold results\n",
    "    temp_X = []\n",
    "\n",
    "    # Get input song array size\n",
    "    xshape = X.shape[0]\n",
    "    chunk = int(xshape*window)\n",
    "    offset = int(chunk*(1.-overlap))\n",
    "    \n",
    "    # Split the song and create new ones\n",
    "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
    "    for s in spsong:\n",
    "        temp_X.append(s)\n",
    "\n",
    "    return np.array(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(y, sr, n_fft=1024, hop_length=512):\n",
    "    \"\"\"\n",
    "    Get selected features for a song using numpy and librosa\n",
    "    \"\"\"\n",
    "\n",
    "    # Selected features:\n",
    "    features = {'centroid': None, 'roloff': None, 'flux': None, 'rmse': None, 'zcr': None, 'chroma': None}\n",
    "    \n",
    "    # Using librosa to calculate the features\n",
    "    features['centroid'] = librosa.feature.spectral_centroid(y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel()\n",
    "    features['roloff'] = librosa.feature.spectral_rolloff(y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel()\n",
    "    features['zcr'] = librosa.feature.zero_crossing_rate(y, frame_length=n_fft, hop_length=hop_length).ravel()\n",
    "    features['rmse'] = librosa.feature.rms(y, frame_length=n_fft, hop_length=hop_length).ravel()\n",
    "    features['flux'] = librosa.onset.onset_strength(y=y, sr=sr).ravel()\n",
    "    features['chroma'] = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel()\n",
    "    \n",
    "    # Treatment of MFCC feature\n",
    "    mfcc = librosa.feature.mfcc(y, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    for idx, v_mfcc in enumerate(mfcc):\n",
    "        features[f'mfcc_{idx}'] = v_mfcc.ravel()\n",
    "        \n",
    "    # Calculate statistics for each feature:\n",
    "    def get_moments(descriptors):\n",
    "        result = {}\n",
    "        for k, v in descriptors.items():\n",
    "            result[f'{k}_mean'] = np.mean(v)\n",
    "            result[f'{k}_std'] = np.std(v)\n",
    "            result[f'{k}_kurtosis'] = kurtosis(v)\n",
    "            result[f'{k}_skew'] = skew(v)\n",
    "        return result\n",
    "    \n",
    "    dict_agg_features = get_moments(features)\n",
    "    \n",
    "    # Calculating one more feature:\n",
    "    dict_agg_features['tempo'] = librosa.beat.tempo(y, sr=sr)[0]\n",
    "    \n",
    "    return dict_agg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_process_labelled(src_dir, window=0.2, overlap=0.5, debug=True):\n",
    "    \"\"\"\n",
    "    Read and process labelled songs (train/test data, demo test data)\n",
    "    \"\"\"\n",
    "\n",
    "    arr_features = []\n",
    "\n",
    "    # Read files from the folders\n",
    "    for x, _ in GENRES.items():\n",
    "        folder = src_dir + x\n",
    "    \n",
    "        for root, subdirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                # Read the audio file\n",
    "                file_name = folder + \"/\" + file\n",
    "                signal, sr = librosa.load(file_name)\n",
    "                signal = signal[:660000]\n",
    "                \n",
    "                # Debug process\n",
    "                if debug:\n",
    "                    print(f\"Reading file: {file_name}\")\n",
    "                    \n",
    "                # Split songs:\n",
    "                samples = split_songs(signal, window, overlap)\n",
    "\n",
    "                # Append the result to the data structure\n",
    "                for s in samples:\n",
    "                    features = get_features(s, sr)\n",
    "                    features['genre'] = GENRES[x]\n",
    "                    arr_features.append(features)\n",
    "\n",
    "    return arr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of dicts with features of train data, convert to dataframe and then save as .csv:\n",
    "\n",
    "features_train = read_process_labelled(AUDIO_DIR, debug=True)\n",
    "df_train = pd.DataFrame(features_train)\n",
    "df_train.to_csv('../Features/dataset_features/data_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of dicts with features of test data, convert to dataframe and then save as .csv:\n",
    "\n",
    "#.csv for original song:\n",
    "features_t1 = read_process_labelled(TEST_DIR, window=1, overlap=0, debug=True)\n",
    "df_t1 = pd.DataFrame(features_t1)\n",
    "df_t1.to_csv('../Features/test_songs_features/test_features.csv', index=False)\n",
    "\n",
    "#.csv for original song split into 3 different songs:\n",
    "features_t2 = read_process_labelled(TEST_DIR, window=1/3, overlap=0, debug=True)\n",
    "df_t2 = pd.DataFrame(features_t2)\n",
    "df_t2.to_csv('../Features/test_songs_features/test_features_split.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
